---
layout:     post
title:      "what are colleges *really* looking for?"
subtitle:   "tl;dr orz != admit, but rng = admit"
date:       2025-12-3 23:00:00
author:     "jasonzeng124"
header-img: "img/post-bg-2015.jpg"
catalog: true
mathjax: true
alter: 0
tags:
    - Pinned
    - College
---

Here, I have two hypothetical college apps awards. One took me the greater part of 3 years of grinding, and the other took me around 5 minutes. Can you guess which?


> 1. USA Computing Olympiad Finalist: Top 20 in US; attended national IOI training & selection camp


> 1. Intl. Math Optimization Challenge: 27th place among ~200 teams worldwide in month-long competition.


<details> <summary>Answer: (click to reveal)</summary>
the second one, i just vibe coded the most simple naive solution and submitted it. there are 29 teams with positive score, and we are 27th. the reason is that this is their first year, and not many people know about this competition, unfortunately
</details>

and bam, in 5 minutes I just got an award that could quite plausibly be better than 99.9% of awards on our school's college apps. to be clear, this is not bragging or anything, just an exposition of the strange reality of college apps.

*note: IIMOC is still ongoing, this is just an illustration*

Ok, I'm actually going to try later on IIMOC (or maybe not, but I'm not here for the placement / whatever, but rather to actually tryhard this just for the fun of it). Its just that my friends were joking about this, and I realized that it's very much not a joke. I can see real people shamelessly writing this (ok, maybe these people are not real, but whatever).

Note: I have nothing against IIMOC; I think it's a great initiative and I really like heuristic challenges and hope that more of this will happen in the future. (consider signing up, the challenge looks pretty fun, plus it's 100% a legit competition, just newer and not very well-known)

I'm just taking this as an example. I will personally not include this in my application, for reasons. Some of my friends might (and they are correct to do so). I also don't care at all about the award, I'm just participating for fun.

-----

So in this blog, I hope to explore the process of college admissions, and hopefully get to peek at what really happens and what colleges really are looking for.

Note: I really don't know any more than anyone else. I don't have any more information than anyone else. This is just my own take and some guesses, from what I do know.


#### Preliminaries

So first, what goes into a college application? This is pretty standard knowledge:

- SAT/ACT scores
- GPA & transcript
- Awards (around 5-10)
- Activities (around 5-10)
- Essays
- Letters of recommendation

That's it. isn't it a lot?

Lets take a more in-depth look at each.


#### Methodology, kind of.

Some assumptions and methods:

1. We assume students are to be compared, and generally, the better student by some scale will be more likely to be admitted. (This is actually being too nice. We assume this axiom, but if you drop it, things only look more RNG)
2. We assume you can roughly form a score by adding the score from different parts of an application, and they are roughly independent (well they aren't entirely independent, but this helps with isolating stuff)
3. We care mostly about so-called honors students. After all, this is where most of the contention about college apps comes in. Honors, here, is like around top 5% or top 30, ish, in my school, will vary based on school.
4. There is a ground truth. And we want to see how stuff is related to the ground truth.
5. We'll look at the variance of each metric, and its correlation with the ground truth. And the range that it will be effective in.


#### Standardized tests

Suppose you wanted to measure the temperature on a hot day. Which one would you choose, a thermometer that goes to 100 F, or one that goes to 200 F?

It looks like Collegeboard and the ACT both chose the 100 F one. And what do they do when the temperature exceeds 100 F? Looks like collegeboard made a new digital SAT, with a range of.... *drumroll* .... 100 F, wow!

Oh, and we are going to measure as many times as we want, and take the best one. Ok, this isn't that bad, but ideally, retakes should be restricted to X retakes where X is small. Unlimited is just somewhat absurd.

Ok, to be fair it does measure pretty well below 100 F, and in general the college admissions system works relatively well for these students. But here, we will look at what happens when you exceed 100 F, as a lot of students do.

Here, standardized tests are mostly just noise, with not so much signal in the high-score range. It's only very loosely correlated to ground truth in like 1450+ range, and becomes basically useless in the 1550+ range.

So: low variance, low correlation, low range.

#### GPA & transcript

Ok, let's get to the point here. GPA is not comparable across schools. It's like trying to compare Farenheit thermometers and Celsuis thermometers without conversion. The scales are all different everywhere.

Some schools will recalculate GPA. But coursework and grades are simply not comparable across schools either. A nearby school has much harder and more work, and harsher grading than ours. Another school has like 17 valedictorians.
They are not comparable in a school, either. Choice of coursework and luck of the draw in teachers matters so much, you can attribute even >10 points difference between teachers at our school. (i, fortunately, probably have the best luck out of the entire school LOL)

Also, inflation hurts this, as it gives less real information to these metrics.

It's simply not comparable. Trying to compare them is just not that informative. That being said, they do exhibit some correlation to ground truth, and probably are somewhat better than SAT in the honors student range.

medium variance, medium-low correlation, medium-low range.

#### Awards / Activities

These are the same, really, with only somewhat superficial differences.

We already talked about this a bit. But essentially, *you* are the one who has to fill out awards, and it's not very easy for AOs to distinguish between high quality awards (like olympiads), not-so-high quality awards (like going to an intl. comp with 10 teams), and flat out bad-quality awards. Why? because when you word it on paper, it's easy to make it look better than it really is, and AO's don't really have the time to check.

So we see that quality of awards is only like loosely correlated with the ground truth.

Great. how about the quantity? Again, they are loosely correlated, with similar reasons.

That being said, activites are probably one of the better ways to distinguish students that are harder to distinguish by the above, because at this level you can't distinguish between strength by what happens in school, really. Most schools just aren't hard enough for this. You have to look outside of school.

And indeed, this does do a reasonable job of distinguishing students. A student with olympiad medals will have a stronger awards section than one with more generic awards like honor roll, ap scholar, etc, no matter how you try to word it. Both the range and the variance are much higher.

medium-high variance, medium-high correlation, high range.

#### Essays

Essays are very much like awards and activities, in that you fill it out.

My mental model of essays is that AOs will extract some sort of semantic embedding vector, and mentally compute the dot product between this and what they are looking for. Or like matmul and softmax or smth similar.

But really, a lot of this is subjective to the reader and thus high variance (multiple readers helps with this a bit). And the correlation is probably ok, but not that high, after all, you are trying to compress your personality into like 1k words, whatever that means.

high variance, medium correlation, what does range mean???

#### Recommendations

I haven't really seen enough of these. They are probably somewhat varied by teacher and related factors. But I'd say correlation is between medium to high, depending on other factors. Also, not *that* much is visible to recommenders, so they don't have as high range as awards get.

medium variance, medium-high correlation, medium range.


#### Summary, ish

So a summary:

| category            | variance    | correlation | range      |
| :------------------ | :---------- | :---------- | :--------- |
| standardized tests  | low         | low         | low        |
| gpa / transcript    | medium      | medium-low  | medium-low |
| awards / activities | medium-high | medium-high | high       |
| essays              | high        | medium      | ???        |
| recommendations     | medium      | medium-high | medium     |

Now, I wish there was some low-variance, high correlation, high range category on here. There is not.

So what does this tell us? Suppose that colleges intend to pick the best students, then they don't actually have that much information to look at. The amount of variance by itself, should, (I think), cause admissions to be fairly random. *That is, even if college were purely a meritocracy, it'd be a rather noisy meritocracy.*

And then you add in the steering vectors of essays. And then other factors such as legacy admissions or first-generation students or athletics etc. And others. (Note: none of this is an opinion. it's all fact.) Then, the variance and RNG increases even more.

Then, take into account that colleges are not selecting the top N students. They are selecting a class, whatever that means. What that means for us is more RNG.

And after everything, this looks more like selecting K students (not necessarily uniformly) at randomly from the top M students, where $M \gg K$. This means, if you aren't one of the M, your chances are pretty low, but if you are, your chances are higher but nowhere near guaranteed.


That being said, RNG is not necessarily a bad thing, to some extent building a class is important. But to us students it does kind of suck.

to be continued...